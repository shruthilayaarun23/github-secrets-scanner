name: Multi-Repository Secret Scanner

on:
  push:
    branches: [ main, master ]
  schedule:
    - cron: '0 2 * * *'
  workflow_dispatch:

permissions:
  contents: write
  issues: write

jobs:
  scan-all-repositories:
    name: Scan All Repositories
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout scanner repo
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'
      
      - name: Install Trivy  
        run: |
          sudo apt-get update
          sudo apt-get install -y wget apt-transport-https gnupg lsb-release
          wget -qO - https://aquasecurity.github.io/trivy-repo/deb/public.key | sudo apt-key add -
          echo "deb https://aquasecurity.github.io/trivy-repo/deb $(lsb_release -sc) main" | sudo tee -a /etc/apt/sources.list.d/trivy.list
          sudo apt-get update
          sudo apt-get install -y trivy
      
      - name: Install Python dependencies
        run: pip install boto3 requests
      
      - name: Scan all repositories
        env:
          GITHUB_TOKEN: ${{ secrets.SCAN_TOKEN }}
          GITHUB_USERNAME: shruthilayaarun23
        run: |
          python << 'PYTHON_SCRIPT'
          import json
          import os
          import requests
          import subprocess
          from pathlib import Path
          from datetime import datetime
          
          GITHUB_TOKEN = os.environ['GITHUB_TOKEN']
          GITHUB_USERNAME = os.environ['GITHUB_USERNAME']
          
          headers = {
              'Authorization': f'token {GITHUB_TOKEN}',
              'Accept': 'application/vnd.github.v3+json'
          }
          
          print("=" * 70)
          print("MULTI-REPOSITORY SECRET SCANNER")
          print("=" * 70)
          
          # Fetch all repositories
          print(f"\n[*] Fetching repositories for {GITHUB_USERNAME}...")
          response = requests.get(
              f'https://api.github.com/user/repos?per_page=100&affiliation=owner',
              headers=headers
          )
          
          if response.status_code != 200:
              print(f"[ERROR] Failed to fetch repos: {response.status_code}")
              exit(1)
          
          repos = response.json()
          print(f"[✓] Found {len(repos)} repositories")
          
          # Exclude the scanner repo itself
          repos = [r for r in repos if r['name'] != 'github-secrets-scanner']
          
          all_secrets = []
          scan_results = []
          
          # Scan each repository
          for i, repo in enumerate(repos, 1):
              repo_name = repo['name']
              repo_url = repo['clone_url']
              
              print(f"\n[{i}/{len(repos)}] Scanning: {repo_name}")
              print(f"    URL: {repo_url}")
              
              # Clone repository
              clone_dir = f"temp-{repo_name}"
              try:
                  subprocess.run(['git', 'clone', '--depth', '1', repo_url, clone_dir],
                                check=True, capture_output=True, timeout=60)
                  
                  # Run Trivy scan
                  result = subprocess.run([
                      'trivy', 'fs', clone_dir,
                      '--scanners', 'secret',
                      '--severity', 'HIGH,CRITICAL',
                      '--format', 'json',
                      '--quiet'
                  ], capture_output=True, text=True, timeout=120)
                  
                  secret_count = 0
                  repo_secrets = []
                  
                  if result.stdout:
                      try:
                          trivy_data = json.loads(result.stdout)
                          
                          for scan_result in trivy_data.get('Results', []):
                              for secret in scan_result.get('Secrets', []):
                                  secret_count += 1
                                  secret_info = {
                                      'repository': repo_name,
                                      'file': scan_result.get('Target', 'unknown'),
                                      'line': secret.get('StartLine', 0),
                                      'title': secret.get('Title', 'Unknown'),
                                      'severity': secret.get('Severity', 'UNKNOWN'),
                                      'rule_id': secret.get('RuleID', 'unknown')
                                  }
                                  repo_secrets.append(secret_info)
                                  all_secrets.append(secret_info)
                      except json.JSONDecodeError:
                          print(f"    [WARNING] Could not parse Trivy output")
                  
                  if secret_count > 0:
                      print(f"    [!] Found {secret_count} secrets")
                  else:
                      print(f"    [✓] No secrets found")
                  
                  scan_results.append({
                      'repository': repo_name,
                      'secrets_found': secret_count,
                      'secrets': repo_secrets,
                      'status': 'success'
                  })
                  
                  # Cleanup
                  subprocess.run(['rm', '-rf', clone_dir], check=True)
                  
              except subprocess.TimeoutExpired:
                  print(f"    [ERROR] Timeout scanning repository")
                  scan_results.append({
                      'repository': repo_name,
                      'secrets_found': 0,
                      'secrets': [],
                      'status': 'timeout'
                  })
              except Exception as e:
                  print(f"    [ERROR] {str(e)}")
                  scan_results.append({
                      'repository': repo_name,
                      'secrets_found': 0,
                      'secrets': [],
                      'status': 'failed',
                      'error': str(e)
                  })
          
          # Save consolidated report
          report = {
              'metadata': {
                  'scan_date': datetime.now().isoformat(),
                  'total_repositories': len(repos),
                  'total_secrets': len(all_secrets),
                  'scanner': 'Multi-Repository Scanner'
              },
              'secrets': all_secrets,
              'scan_results': scan_results
          }
          
          Path('multi-repo-scan-results.json').write_text(json.dumps(report, indent=2))
          
          print("\n" + "=" * 70)
          print("SCAN SUMMARY")
          print("=" * 70)
          print(f"  Total Repositories Scanned: {len(repos)}")
          print(f"  Total Secrets Found: {len(all_secrets)}")
          print(f"  Repositories with Secrets: {len([r for r in scan_results if r['secrets_found'] > 0])}")
          print("=" * 70)
          
          # Save for next job
          with open('secrets_found.txt', 'w') as f:
              f.write(str(len(all_secrets)))
          
          PYTHON_SCRIPT
      
      - name: Upload scan results
        uses: actions/upload-artifact@v4
        with:
          name: multi-repo-scan-results
          path: multi-repo-scan-results.json
          retention-days: 90
      
      - name: Check if secrets found
        id: check-secrets
        run: |
          SECRET_COUNT=$(cat secrets_found.txt)
          echo "secret-count=$SECRET_COUNT" >> $GITHUB_OUTPUT
          
          if [ "$SECRET_COUNT" -gt 0 ]; then
            echo "secrets-found=true" >> $GITHUB_OUTPUT
          else
            echo "secrets-found=false" >> $GITHUB_OUTPUT
          fi
    
    outputs:
      secrets-found: ${{ steps.check-secrets.outputs.secrets-found }}
      secret-count: ${{ steps.check-secrets.outputs.secret-count }}

  exploitation-simulation:
    name: LocalStack Exploitation
    runs-on: ubuntu-latest
    needs: scan-all-repositories
    if: needs.scan-all-repositories.outputs.secrets-found == 'true'
    
    services:
      localstack:
        image: localstack/localstack:latest
        ports:
          - 4566:4566
        env:
          SERVICES: s3,ec2,iam
        options: >-
          --health-cmd "curl -f http://localhost:4566/_localstack/health || exit 1"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Download scan results
        uses: actions/download-artifact@v4
        with:
          name: multi-repo-scan-results
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'
      
      - name: Install dependencies
        run: pip install boto3
      
      - name: Wait for LocalStack
        run: |
          echo "Waiting for LocalStack..."
          for i in {1..30}; do
            if curl -f http://localhost:4566/_localstack/health 2>/dev/null; then
              echo "LocalStack ready!"
              break
            fi
            sleep 2
          done
      
      - name: Run exploitation simulation
        run: |
          python << 'PYTHON_SCRIPT'
          import json
          import boto3
          from pathlib import Path
          from datetime import datetime
          
          ENDPOINT = "http://localhost:4566"
          
          print("=" * 70)
          print("MULTI-REPO EXPLOITATION SIMULATION")
          print("=" * 70)
          
          # Load scan results
          report = json.loads(Path('multi-repo-scan-results.json').read_text())
          total_secrets = report['metadata']['total_secrets']
          
          print(f"\n[*] Testing {total_secrets} secrets across multiple repositories")
          
          # Setup LocalStack
          s3 = boto3.client('s3', endpoint_url=ENDPOINT,
                           aws_access_key_id='test',
                           aws_secret_access_key='test',
                           region_name='us-east-1')
          
          # Create vulnerable environment
          print("\n[*] Creating vulnerable AWS environment...")
          buckets = [
              'company-customer-data',
              'production-backups',
              'financial-reports-2024',
              'employee-records',
              'api-keys-vault'
          ]
          
          for bucket in buckets:
              try:
                  s3.create_bucket(Bucket=bucket)
                  s3.put_object(Bucket=bucket, Key='sensitive-data.csv',
                               Body=f'CONFIDENTIAL: Data from {bucket}')
                  print(f"  [+] Created: {bucket}")
              except: pass
          
          # Simulate exploitation
          print("\n[ATTACK] Simulating credential exploitation...")
          result = s3.list_buckets()
          bucket_count = len(result['Buckets'])
          
          print(f"  [!] Accessed {bucket_count} S3 buckets")
          
          files_stolen = 0
          for bucket in result['Buckets']:
              objects = s3.list_objects_v2(Bucket=bucket['Name'])
              if 'Contents' in objects:
                  for obj in objects['Contents']:
                      print(f"  [STOLEN] {bucket['Name']}/{obj['Key']}")
                      files_stolen += 1
          
          # Calculate impact
          repos_affected = len([r for r in report['scan_results'] if r['secrets_found'] > 0])
          
          exploit_results = {
              'timestamp': datetime.now().isoformat(),
              'secrets_tested': total_secrets,
              'repositories_affected': repos_affected,
              'buckets_accessed': bucket_count,
              'files_exfiltrated': files_stolen,
              'estimated_damage': f'$1.5M - $10M (across {repos_affected} repositories)',
              'exploitation_successful': True
          }
          
          Path('exploitation-results.json').write_text(json.dumps(exploit_results, indent=2))
          
          print(f"\n[IMPACT] Repositories affected: {repos_affected}")
          print(f"[IMPACT] Total secrets: {total_secrets}")
          print(f"[IMPACT] Files stolen: {files_stolen}")
          print(f"[IMPACT] Estimated damage: {exploit_results['estimated_damage']}")
          print("=" * 70)
          PYTHON_SCRIPT
      
      - name: Upload exploitation results
        uses: actions/upload-artifact@v4
        with:
          name: exploitation-results
          path: exploitation-results.json

  create-summary-issue:
    name: Create Summary Issue
    runs-on: ubuntu-latest
    needs: [scan-all-repositories, exploitation-simulation]
    if: needs.scan-all-repositories.outputs.secrets-found == 'true'
    
    steps:
      - name: Download all results
        uses: actions/download-artifact@v4
        with:
          pattern: '*'
          merge-multiple: true
      
      - name: Create consolidated security issue
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            
            const scanReport = JSON.parse(fs.readFileSync('multi-repo-scan-results.json', 'utf8'));
            const exploitReport = JSON.parse(fs.readFileSync('exploitation-results.json', 'utf8'));
            
            const reposWithSecrets = scanReport.scan_results.filter(r => r.secrets_found > 0);
            
            let repoTable = reposWithSecrets
              .sort((a, b) => b.secrets_found - a.secrets_found)
              .map(r => `| ${r.repository} | ${r.secrets_found} | CRITICAL |`)
              .join('\n');
            
            const issueBody = `
            ##  MULTI-REPOSITORY SECURITY SCAN RESULTS
            
            **Scan Date:** ${scanReport.metadata.scan_date}
            
            ###  Executive Summary
            
            - **Total Repositories Scanned:** ${scanReport.metadata.total_repositories}
            - **Repositories with Secrets:** ${reposWithSecrets.length}
            - **Total Secrets Found:** ${scanReport.metadata.total_secrets}
            
            ###  Exploitation Simulation (LocalStack)
            
            - **Repositories Compromised:** ${exploitReport.repositories_affected}
            - **AWS Resources Accessed:** ${exploitReport.buckets_accessed} S3 buckets
            - **Files Exfiltrated:** ${exploitReport.files_exfiltrated}
            - **Estimated Impact:** ${exploitReport.estimated_damage}
            
            ###  Affected Repositories
            
            | Repository | Secrets Found | Risk Level |
            |------------|---------------|------------|
            ${repoTable}
            
            ### IMMEDIATE ACTIONS REQUIRED
            
            1. Rotate ALL exposed credentials
            2. Remove hardcoded secrets
            3. Implement secret management
            4. Review access logs
            
            [View Full Report](https://github.com/${context.repo.owner}/${context.repo.repo}/actions/runs/${context.runId})
            `;
            
            await github.rest.issues.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              title: `${scanReport.metadata.total_secrets} Secrets Found Across ${reposWithSecrets.length} Repositories`,
              body: issueBody,
              labels: ['security', 'critical']
            });
  export-metrics:
    name: Export Prometheus Metrics
    runs-on: ubuntu-latest
    needs: [scan-all-repositories, exploitation-simulation]
    if: always()
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.SCAN_TOKEN }}
      
      - name: Download artifacts
        uses: actions/download-artifact@v4
        with:
          pattern: '*'
          merge-multiple: true
        continue-on-error: true
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'
      
      - name: Generate Prometheus metrics
        run: |
          python3 << 'EOF'
          import json
          from pathlib import Path
          from datetime import datetime
          
          try:
              scan_data = json.loads(Path('multi-repo-scan-results.json').read_text())
          except:
              scan_data = {'metadata': {'total_secrets': 0}, 'secrets': [], 'scan_results': []}
          
          try:
              exploit_data = json.loads(Path('exploitation-results.json').read_text())
          except:
              exploit_data = {'buckets_accessed': 0, 'files_exfiltrated': 0}
          
          secrets = scan_data.get('secrets', [])
          scan_results = scan_data.get('scan_results', [])
          
          critical = len([s for s in secrets if s.get('severity') == 'CRITICAL'])
          high = len([s for s in secrets if s.get('severity') == 'HIGH'])
          total_repos = len(scan_results)
          repos_with_secrets = len([r for r in scan_results if r.get('secrets_found', 0) > 0])
          
          metrics = f"""secret_scanner_total_secrets {len(secrets)}
secret_scanner_critical_secrets {critical}
secret_scanner_high_secrets {high}
secret_scanner_repositories_scanned {total_repos}
secret_scanner_repositories_with_secrets {repos_with_secrets}
secret_scanner_exploitation_buckets {exploit_data.get('buckets_accessed', 0)}
secret_scanner_exploitation_files {exploit_data.get('files_exfiltrated', 0)}
secret_scanner_timestamp {int(datetime.now().timestamp())}
"""
          
          Path('metrics.prom').write_text(metrics)
          print(f"Metrics generated: {len(secrets)} secrets found")
          EOF
      
      - name: Create metrics directory
        run: |
          mkdir -p prometheus/metrics
          cp metrics.prom prometheus/metrics/latest.prom
      
      - name: Commit metrics to repo
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git add prometheus/metrics/
          git commit -m "Update Prometheus metrics [skip ci]" || echo "No changes"
          git push || echo "Push failed"
      
      - name: Upload metrics artifact
        uses: actions/upload-artifact@v4
        with:
          name: prometheus-metrics
          path: |
            metrics.prom
            prometheus/metrics/